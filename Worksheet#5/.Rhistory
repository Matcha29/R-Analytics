link_list[i] <- paste0("https://imdb.com", link_list[i])
}
# Convert to a dataframe
links <- as.data.frame(link_list)
names(links) <- "link"
rank_title <- data.frame(
rank_title = split_df)
# combining the dataframe
scrape_df <- data.frame(rank_title)
names(scrape_df) <- c("Rank", "Title")
head(scrape_df)
scrape_df
write.csv(scrape_df,file = "D:/RAnalytics/Worksheet#5/top250.csv")
# Additional Extraction
current_row <- 1
imdb_top_25 <- data.frame()
# for this example, we will get only the content for the 1st twenty-five rows
for (row in 1:25) {
# Get the URL from the "href" column
url <- links$link[current_row]
# Skip if the URL is empty or improperly constructed
if (url == "" || is.na(url)) {
next
}
# Read the HTML content of the webpage
session2 <- bow(url, user_agent = "Educational")
webpage <- scrape(session2)
# Extract the rating using the appropriate CSS selector
rating <- html_text(html_nodes(webpage, ".sc-d541859f-1.imUuxf"))
if (length(rating) == 0) {
next
} else {
rating <- rating[1]
}
# Extracting votecount
votecount <- html_text(html_nodes(webpage, 'div.sc-d541859f-3.dwhNqC'))
if (length(votecount) == 0) {
next
} else {
votecount <- votecount[1]
}
# Extracting number of episodes and year released
numofEps_year <- html_text(html_nodes(webpage, xpath = "//span[contains(text(), 'episodes')]"))
if (length(numofEps_year) == 0) {
next
} else {
numofEps_year <- numofEps_year[1]
numofEps <- sub("episodes.*", "episodes", numofEps_year)
year_released <- sub(".*episodes • ", "", numofEps_year)
}
# Print or save the extracted data
cat("Rating for", url, "is:", rating, "vote count is", votecount, "number of episodes is", numofEps, "year released is", year_released, "\n")
# Store the results
imdb_top_25[current_row, 1] <- rating
imdb_top_25[current_row, 2] <- votecount
imdb_top_25[current_row, 3] <- numofEps
imdb_top_25[current_row, 4] <- year_released
# Move to the next row
current_row <- current_row + 1
# Add some delay to avoid overloading the server (optional)
Sys.sleep(3)
}
install.packages("kableExtra")
install.packages("polite")
names(imdb_top_25) <- c("Rating","VoteCount","Number of Episodes", "Year Released")
write.csv(imdb_top_25,file = "D:/RAnalytics/Worksheet#5/imdb_top_25.csv")
# Combine with the previous dataframe
imdb_top_25 <- data.frame(
scrape_df, imdb_top_25)
write.csv(imdb_top_25,file = "D:/RAnalytics/Worksheet#5/imdb_top_250.csv")
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8)
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 8)
install.packages("polite")
options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("rvest")
install.packages("httr")
install.packages("httr2")
install.packages("httr")
install.packages("rvest")
install.packages("parallelly", type = "source")
install.packages("polite")
install.packages("kableExtra")
library(rvest)
library(httr)
library(parallelly)
library(dplyr)
library(polite)
# Specifying the url for desired website to be scraped
url <- 'https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250'
# asking permission to scrape
install.packages("kableExtra")
session <- bow(url, user_agent = "Educational")
install.packages("polite")
install.packages("parallelly", type = "source")
install.packages("rvest")
session
# creating objects for the dataset
rank_title <- character(0)
links <- character(0)
# title list
title_list <- scrape(session) %>%
html_nodes('h3.ipc-title__text') %>%
html_text
install.packages("rvest")
title_list
class(title_list)
title_list_sub <- as.data.frame(title_list[2:26])
head(title_list_sub)
tail(title_list_sub)
title_list_sub
# ranks
colnames(title_list_sub) <- "ranks"
# split the string(rank and title)
split_df <- strsplit(as.character(title_list_sub$ranks),".",fixed = TRUE)
split_df <- data.frame(do.call(rbind,split_df))
# rename and delete columns
# deleting columns 3 and 4 since it duplicated the columns
split_df <- split_df[-c(3:4)]
# renaming column 1 and 2
colnames(split_df) <- c("Ranks","Title")
# structure of splif_df
str(split_df)
head(split_df)
split_df
rank_title <- data.frame(
rank_title = split_df)
write.csv(rank_title,file = "D:/RAnalytics/Worksheet#5/title.csv")
# Extracting link
# extracting for link of every movie
link_list <- scrape(session) %>%
html_nodes('a.ipc-title-link-wrapper') %>%
html_attr('href')
# Ensure no NA values
link_list <- link_list[!is.na(link_list) & link_list != ""]
# Construct full URLs
for (i in 1:length(link_list)) {
link_list[i] <- paste0("https://imdb.com", link_list[i])
}
# Convert to a dataframe
links <- as.data.frame(link_list)
names(links) <- "link"
rank_title <- data.frame(
rank_title = split_df)
# combining the dataframe
scrape_df <- data.frame(rank_title)
names(scrape_df) <- c("Rank", "Title")
head(scrape_df)
scrape_df
write.csv(scrape_df,file = "D:/RAnalytics/Worksheet#5/top250.csv")
imdb_top_25 <- data.frame()
# for this example, we will get only the content for the 1st twenty-five rows
for (row in 1:25) {
# Get the URL from the "href" column
url <- links$link[row]
# Skip if the URL is empty or improperly constructed
if (url == "" || is.na(url)) {
next
}
# Read the HTML content of the webpage
session2 <- bow(url, user_agent = "Educational")
webpage <- scrape(session2)
# Extract the rating using the appropriate CSS selector
rating <- html_text(html_nodes(webpage, ".sc-d541859f-1.imUuxf"))
if (length(rating) == 0) {
next
} else {
rating <- rating[1]
}
# Extracting votecount
votecount <- html_text(html_nodes(webpage, 'div.sc-d541859f-3.dwhNqC'))
if (length(votecount) == 0) {
next
} else {
votecount <- votecount[1]
}
# Extracting number of episodes and year released
numofEps_year <- html_text(html_nodes(webpage, xpath = "//span[contains(text(), 'episodes')]"))
if (length(numofEps_year) == 0) {
next
} else {
numofEps_year <- numofEps_year[1]
numofEps <- sub("episodes.*", "episodes", numofEps_year)
year_released <- sub(".*episodes • ", "", numofEps_year)
}
# Print or save the extracted data
cat("Rating for", url, "is:", rating, "vote count is", votecount, "number of episodes is", numofEps, "year released is", year_released, "\n")
# Store the results
imdb_top_25 <- rbind(imdb_top_25, data.frame(Rating = rating, VoteCount = votecount, Number.of.Episodes = numofEps, Year.Released = year_released))
# Move to the next row
# Add some delay to avoid overloading the server (optional)
Sys.sleep(3)
}
names(imdb_top_25) <- c("Rating","VoteCount","Number of Episodes", "Year Released")
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_25.csv")
# Combine with the previous dataframe
imdb_top_25 <- data.frame(
scrape_df, imdb_top_25)
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_250.csv")
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8)
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 8)
imdb_top_25 <- data.frame()
# for this example, we will get only the content for the 1st twenty-five rows
for (row in 1:25) {
# Get the URL from the "href" column
url <- links$link[row]
# Skip if the URL is empty or improperly constructed
if (url == "" || is.na(url)) {
next
}
# Read the HTML content of the webpage
session2 <- bow(url, user_agent = "Educational")
webpage <- scrape(session2)
# Extract the rating using the appropriate CSS selector
rating <- html_text(html_nodes(webpage, ".sc-d541859f-1.imUuxf"))
if (length(rating) == 0) {
next
} else {
rating <- rating[1]
}
# Extracting votecount
votecount <- html_text(html_nodes(webpage, 'div.sc-d541859f-3.dwhNqC'))
if (length(votecount) == 0) {
next
} else {
votecount <- votecount[1]
}
# Extracting number of episodes and year released
numofEps_year <- html_text(html_nodes(webpage, xpath = "//span[contains(text(), 'episodes')]"))
if (length(numofEps_year) == 0) {
next
} else {
numofEps_year <- numofEps_year[1]
numofEps <- sub("episodes.*", "episodes", numofEps_year)
year_released <- sub(".*episodes • ", "", numofEps_year)
}
# Print or save the extracted data
cat("Rating for", url, "is:", rating, "vote count is", votecount, "number of episodes is", numofEps, "year released is", year_released, "\n")
# Store the results
imdb_top_25 <- rbind(imdb_top_25, data.frame(Rating = rating, VoteCount = votecount, Number.of.Episodes = numofEps, Year.Released = year_released))
# Add some delay to avoid overloading the server (optional)
Sys.sleep(3)
}
names(imdb_top_25) <- c("Rating","VoteCount","Number of Episodes", "Year Released")
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_25.csv")
# Combine with the previous dataframe
imdb_top_25 <- data.frame(
scrape_df, imdb_top_25)
imdb_top_25 <- data.frame()
# for this example, we will get only the content for the 1st twenty-five rows
for (row in 1:25) {
# Get the URL from the "href" column
url <- links$link[row]
# Skip if the URL is empty or improperly constructed
if (url == "" || is.na(url)) {
next
}
# Read the HTML content of the webpage
session2 <- bow(url, user_agent = "Educational")
webpage <- scrape(session2)
# Extract the rating using the appropriate CSS selector
rating <- html_text(html_nodes(webpage, ".sc-d541859f-1.imUuxf"))
if (length(rating) == 0) {
next
} else {
rating <- rating[1]
}
# Extracting votecount
votecount <- html_text(html_nodes(webpage, 'div.sc-d541859f-3.dwhNqC'))
if (length(votecount) == 0) {
next
} else {
votecount <- votecount[1]
}
# Extracting number of episodes and year released
numofEps_year <- html_text(html_nodes(webpage, xpath = "//span[contains(text(), 'episodes')]"))
if (length(numofEps_year) == 0) {
next
} else {
numofEps_year <- numofEps_year[1]
numofEps <- sub("episodes.*", "episodes", numofEps_year)
year_released <- sub(".*episodes • ", "", numofEps_year)
}
# Print or save the extracted data
cat("Rating for", url, "is:", rating, "vote count is", votecount, "number of episodes is", numofEps, "year released is", year_released, "\n")
# Store the results
imdb_top_25 <- rbind(imdb_top_25, data.frame(Rating = rating, VoteCount = votecount, Number.of.Episodes = numofEps, Year.Released = year_released))
# Add some delay to avoid overloading the server (optional)
Sys.sleep(3)
}
names(imdb_top_25) <- c("Rating","VoteCount","Number of Episodes", "Year Released")
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_25.csv")
# Combine with the previous dataframe
imdb_top_25 <- data.frame(
scrape_df, imdb_top_25)
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_250.csv")
options(repos = c(CRAN = "https://cran.rstudio.com/"))
install.packages("rvest")
install.packages("httr")
install.packages("httr2")
install.packages("rvest")
install.packages("httr")
install.packages("parallelly", type = "source")
install.packages("polite")
install.packages("kableExtra")
library(rvest)
library(httr)
library(parallelly)
library(dplyr)
library(polite)
# Specifying the url for desired website to be scraped
install.packages("kableExtra")
url <- 'https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250'
install.packages("polite")
install.packages("parallelly", type = "source")
install.packages("httr")
# asking permission to scrape
session <- bow(url, user_agent = "Educational")
session
# creating objects for the dataset
rank_title <- character(0)
links <- character(0)
# title list
title_list <- scrape(session) %>%
html_nodes('h3.ipc-title__text') %>%
html_text
title_list
class(title_list)
title_list_sub <- as.data.frame(title_list[2:26])
head(title_list_sub)
tail(title_list_sub)
title_list_sub
# ranks
colnames(title_list_sub) <- "ranks"
# split the string(rank and title)
split_df <- strsplit(as.character(title_list_sub$ranks),".",fixed = TRUE)
split_df <- data.frame(do.call(rbind,split_df))
# rename and delete columns
# deleting columns 3 and 4 since it duplicated the columns
split_df <- split_df[-c(3:4)]
# renaming column 1 and 2
colnames(split_df) <- c("Ranks","Title")
# structure of splif_df
str(split_df)
head(split_df)
split_df
rank_title <- data.frame(
rank_title = split_df)
write.csv(rank_title,file = "D:/RAnalytics/Worksheet#5/title.csv")
# Extracting link
# extracting for link of every movie
link_list <- scrape(session) %>%
html_nodes('a.ipc-title-link-wrapper') %>%
html_attr('href')
install.packages("httr")
install.packages("parallelly", type = "source")
# Ensure no NA values
link_list <- link_list[!is.na(link_list) & link_list != ""]
# Construct full URLs
for (i in 1:length(link_list)) {
link_list[i] <- paste0("https://imdb.com", link_list[i])
}
# Convert to a dataframe
links <- as.data.frame(link_list)
names(links) <- "link"
rank_title <- data.frame(
rank_title = split_df)
# combining the dataframe
scrape_df <- data.frame(rank_title)
names(scrape_df) <- c("Rank", "Title")
head(scrape_df)
scrape_df
write.csv(scrape_df,file = "D:/RAnalytics/Worksheet#5/top250.csv")
imdb_top_25 <- data.frame()
# for this example, we will get only the content for the 1st twenty-five rows
for (row in 1:25) {
# Get the URL from the "href" column
url <- links$link[row]
# Skip if the URL is empty or improperly constructed
if (url == "" || is.na(url)) {
next
}
# Read the HTML content of the webpage
session2 <- bow(url, user_agent = "Educational")
webpage <- scrape(session2)
# Extract the rating using the appropriate CSS selector
rating <- html_text(html_nodes(webpage, ".sc-d541859f-1.imUuxf"))
if (length(rating) == 0) {
next
} else {
rating <- rating[1]
}
# Extracting votecount
votecount <- html_text(html_nodes(webpage, 'div.sc-d541859f-3.dwhNqC'))
if (length(votecount) == 0) {
next
} else {
votecount <- votecount[1]
}
# Extracting number of episodes and year released
numofEps_year <- html_text(html_nodes(webpage, xpath = "//span[contains(text(), 'episodes')]"))
if (length(numofEps_year) == 0) {
next
} else {
numofEps_year <- numofEps_year[1]
numofEps <- sub("episodes.*", "episodes", numofEps_year)
year_released <- sub(".*episodes • ", "", numofEps_year)
}
# Print or save the extracted data
cat("Rating for", url, "is:", rating, "vote count is", votecount, "number of episodes is", numofEps, "year released is", year_released, "\n")
# Store the results
imdb_top_25 <- rbind(imdb_top_25, data.frame(Rating = rating, VoteCount = votecount, Number.of.Episodes = numofEps, Year.Released = year_released))
# Add some delay to avoid overloading the server (optional)
Sys.sleep(3)
}
install.packages("parallelly", type = "source")
names(imdb_top_25) <- c("Rating","VoteCount","Number of Episodes", "Year Released")
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_25.csv")
# Combine with the previous dataframe
imdb_top_25 <- data.frame(
scrape_df, imdb_top_25)
write.csv(imdb_top_25, file = "D:/RAnalytics/Worksheet#5/imdb_top_250.csv")
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 6) %>%
scroll_box(width = "100%", height = "500px")
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 6)
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8) %>%
landscape()
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 8)
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8) %>%
landscape()
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25), c("Rank", "Title", "Rating", "Year Released")]
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8) %>%
landscape()
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 8)
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
# Displaying with kableExtra
library(kableExtra)
knitr::kable(imdb_top_25,caption = "Extracting Rating, VoteCount, Number of Episodes, Year Released") %>%
kable_classic(full_width = T, html_font = "Cambria") %>%
kable_styling(font_size = 8) %>%
landscape()
# Display top 25 shows only
library(kableExtra)
df_d <- imdb_top_25[c(1:25),]
df_d <- df_d %>%
select_if(~ !all(is.na(.)))
knitr::kable(df_d, caption = "IMDB Top 25 Shows") %>%
kable_classic(full_width = T, html_font = "Arial Narrow") %>%
kable_styling(font_size = 8)
